{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Data Analysis 2023-2024\n",
    "\n",
    "### Andreia Sofia Teixeira\n",
    "\n",
    "## TP Network Science Fundamentals - Part 4\n",
    "\n",
    "Contents:\n",
    "\n",
    "1. Partitions\n",
    "2. Modularity\n",
    "3. Zachary's Karate Club\n",
    "4. Girvan-Newman clustering algorithm\n",
    "\n",
    "#### Based on the tutorial of Chapter 6 of the book *A First Course on Network Science*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitions\n",
    "\n",
    "A **partition** of a graph is a separation of its nodes into disjoint groups. Consider the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "nx.add_cycle(G, [0, 1, 2, 3])\n",
    "nx.add_cycle(G, [4, 5, 6, 7])\n",
    "G.add_edge(0, 7)\n",
    "\n",
    "nx.draw_networkx(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of a partition of these nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = [\n",
    "    {1, 2, 3},\n",
    "    {4, 5, 6},\n",
    "    {0, 7},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that every node in the graph is in exactly one of the sets in the partition. Formally, a partition is a list of sets such that every node is in exactly one set. NetworkX can verify that our partition is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.is_partition(G, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing community detection algorithms, we often make use of a *partition map*, which is a dictionary mapping node names to a partition index. This is useful for quickly comparing if two nodes are in the same cluster in the partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_map = {}\n",
    "for idx, cluster_nodes in enumerate(partition):\n",
    "    for node in cluster_nodes:\n",
    "        partition_map[node] = idx\n",
    "\n",
    "partition_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dictionary, the keys are the node names and two nodes will have the same value if they are in the same partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_map[0] == partition_map[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our partition by drawing the graph with nodes colored by their partition membership:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_colors = [partition_map[n] for n in G.nodes]\n",
    "        \n",
    "nx.draw_networkx(G, node_color=node_colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two trivial partitions:\n",
    "\n",
    "1. The partition with one set containing every node;\n",
    "2. The partition with N sets, each containing a single node.\n",
    "\n",
    "A valid partition thus contains between 1 and N sets.\n",
    "\n",
    "Feel free to experiment by changing the partition above and running the subsequent cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity\n",
    "\n",
    "At a high level, network community detection consists of finding a partition that achieves good separation between the groups of nodes. Before we get into how to find good partitions of a graph, we need an objective -- a way to measure how good the partition is. Modularity is one such objective function.\n",
    "\n",
    "The modularity of a graph partition compares the number of intra-group edges with a random baseline. Higher modularity scores correspond to a higher proportion of intra-group edges, therefore fewer inter-group edges and better separation of groups.\n",
    "\n",
    "For weighted undirected networks, as described in the text, we have\n",
    "\\begin{equation}\n",
    "    Q_w=\\frac{1}{W}\\sum_C \\left(W_C-\\frac{s_C^2}{4W}\\right),\n",
    "    \\label{eq:wmodul}\n",
    "\\end{equation}\n",
    "where \n",
    "* $W$ is the total weight of the links of the network,\n",
    "* $W_C$ the total weight of the internal links of cluster $C$, and\n",
    "* $s_C$ the total strength of the nodes of $C$.\n",
    "\n",
    "The total weight $W$ is half the total strength for the same reason that the number of edges $L$ is half the total degree. While this formula may look a bit complicated, it's straightforward to write code to compute the sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularity(G, partition):\n",
    "    W = sum(G.edges[v, w].get('weight', 1) for v, w in G.edges)\n",
    "    summation = 0\n",
    "    for cluster_nodes in partition:\n",
    "        s_c = sum(G.degree(n, weight='weight') for n in cluster_nodes)\n",
    "        # Use subgraph to count only internal links\n",
    "        C = G.subgraph(cluster_nodes)\n",
    "        W_c = sum(C.edges[v, w].get('weight', 1) for v, w in C.edges)\n",
    "        summation += W_c - s_c ** 2 / (4 * W)\n",
    "    \n",
    "    return summation / W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity(G, partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a partition we would suspect to have higher modularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_2 = [\n",
    "    {0, 1, 2, 3},\n",
    "    {4, 5, 6, 7},\n",
    "]\n",
    "modularity(G, partition_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetworkX function\n",
    "\n",
    "NetworkX provides a modularity function that is more efficient than ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, partition_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zachary's Karate Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing and testing community-detection algorithms, it helps to make use of benchmark networks: graphs with a known, \"natural\" community structure. Perhaps the most famous benchmark graph is Zachary's Karate Club. It contains 34 nodes, representing members of a karate club whose interactions were monitored over a period of three years by researchers. Links in this graph connect individuals interacting outside club activities, a proxy for social ties.\n",
    "\n",
    "During the course of the study, a conflict between the instructor Mr. Hi (node 0) and the president, or Officer (node 33) led to a split of the club into separate groups led by Mr. Hi and Officer. In this case we know whom each member of the group followed after the split, providing empirical community labels: those members who followed Mr. Hi are said to be one community and those following the Officer make up the other.\n",
    "\n",
    "For this graph, we assume that the post-split group composition was largely driven by the social ties: members of the same friend groups would want to be part of the same club after the split. We thus expect a good community-detection algorithm to predict the post-split group composition with high accuracy.\n",
    "\n",
    "Zachary's karate club is such a popular benchmark graph that it has its own function in NetworkX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nx.karate_club_graph()\n",
    "nx.draw_networkx(K, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each node in a NetworkX graph has a dictionary of *attributes* associated with it. This dictionary can hold arbitrary data about a node. We can get the attributes for a single node by giving the node name to the `nodes` object.\n",
    "\n",
    "Each node in this graph has a `'club'` attribute, indicating whether the member followed the instructor or the president after the split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.nodes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize these labels by coloring each node according to its `'club'` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = nx.karate_club_graph()\n",
    "club_color = {\n",
    "    'Mr. Hi': 'orange',\n",
    "    'Officer': 'lightblue',\n",
    "}\n",
    "node_colors = [club_color[K.nodes[n]['club']] for n in K.nodes]\n",
    "nx.draw_networkx(K, node_color=node_colors, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This separation looks good, in that there are relatively few inter-community links as opposed to intra-community links. Let's create a graph partition based on these labels and measure its modularity.\n",
    "\n",
    "We can do this by creating a dictionary of two sets, one for each value of the nodes' `'club'` attribute, then assigning the nodes to the corresponding set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'Mr. Hi': set(),\n",
    "    'Officer': set(),\n",
    "}\n",
    "\n",
    "for n in K.nodes:\n",
    "    club = K.nodes[n]['club']\n",
    "    groups[club].add(n)\n",
    "    \n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the dictionary's `.values()` method, we can get a list of sets that define our partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_partition = list(groups.values())\n",
    "empirical_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.is_partition(K, empirical_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our partition is indeed a valid partition, we can get the modularity of this partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(K, empirical_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively high modularity, which is what we expect.\n",
    "\n",
    "### Comparison to a random partition\n",
    "\n",
    "For the sake of comparison, let's generate a random partition of this network and check its modularity. We would expect a modularity close to zero in this case.\n",
    "\n",
    "First we generate a sample of 17 nodes, half the total number of nodes, and assign them to one community. Our second community then includes the nodes in the graph not in the first community. We can use some set arithmetic to do this concisely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_nodes = random.sample(K.nodes, 17)\n",
    "random_partition = [set(random_nodes),\n",
    "                    set(K.nodes) - set(random_nodes)]\n",
    "random_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this partition and observe that the communities are much less natural-looking, as we would expect from a random assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_node_colors = ['orange' if n in random_nodes else 'lightblue' for n in K.nodes]\n",
    "nx.draw_networkx(K, node_color=random_node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can test the modularity of this partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(K, random_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a random process the modularity won't be exactly zero, but it should be fairly close. Go ahead and repeat the process of generating a random partition and testing its modularity -- it will fluctuate around its mean value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Girvan-Newman clustering\n",
    "\n",
    "Our task in this part will be to implement the Girvan-Newman clustering algorithm. Since NetworkX can do the heavy lifting for us -- computing betweenness centrality -- the code part of the task is relatively straightforward. Most of our effort here is spent interpreting and explaining intermediate results.\n",
    "\n",
    "Recall from the text the Girvan-Newman clustering algorithm:\n",
    "\n",
    "1. Create a partition sequence\n",
    "  1. Calculate the betweenness centrality for all links.\n",
    "  2. Remove the link with largest betweenness and create a partition using connected components.\n",
    "  3. Recalculate the betweenness centrality of the links of the resulting graph.\n",
    "  4. Repeat from step B until no links remain.\n",
    "2. Evaluate each partition in the sequence and choose the one with the highest modularity.\n",
    "\n",
    "During this process, the number of connected components in the graph will increase monotonically as clusters are broken up. Since we are removing one link at a time, the number of connected components can increase by at most one between steps in the sequence -- it's not possible for a single edge to connect more than two nodes, and thus components.\n",
    "\n",
    "We hope that the resulting partition of the graph will approximate its underlying community structure. We'll use the Karate Club graph here because we know the ground-truth community labels and can compare the result obtained from the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "nx.draw_networkx(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a partition sequence\n",
    "### A. Calculate the betweenness centrality for all links\n",
    "\n",
    "NetworkX does the heavy lifting here. All we need to do is understand the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.edge_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dictionary has edge tuples as the keys, and each associated value is the betweenness centrality of that edge. The algorithm to compute the edge betweenness of all edges in a graph costs about the same as calculating it for a single edge, so we'll make use of this dictionary with the computed values for every edge.\n",
    "\n",
    "Once computed for all edges, we can easily get the associated betweenness for a single edge. For example, to get the edge betweenness of the edge between nodes 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "my_edge_betweenness[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that dictionaries also have the `.get` method. This will be used in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness.get((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Remove the link with largest betweenness...\n",
    "\n",
    "Given this dictionary of betweenness values for each edge, we can make use of Python's builtin `max` function to give us the key in this dictionary with the greatest value. Since there is a key in the dictionary for each edge in the graph, the following two expressions are equivalent, but the second one is probably more explicit as to what we're doing with this statement.\n",
    "\n",
    "I'm using the name `my_edge_betweenness` to make clear that this is a dictionary we've named and not a NetworkX function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(my_edge_betweenness, key=my_edge_betweenness.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(G.edges(), key=my_edge_betweenness.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then the edge we want to remove at this step in the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "most_valuable_edge = max(G.edges(), key=my_edge_betweenness.get)\n",
    "G.remove_edge(*most_valuable_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"splat\" in the last statement above `G.remove_edge(*most_valuable_edge)` performs tuple unpacking into the arguments of a function. For example, if our most valuable edge is `(0, 31)`,\n",
    "\n",
    "    G.remove_edge(*most_valuable_edge)\n",
    "is the same as\n",
    "    \n",
    "    G.remove_edge(most_valuable_edge[0], most_valuable_edge[1])\n",
    "or\n",
    "\n",
    "    G.remove_edge(0, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. (cont'd) ...and create a partition using connected components\n",
    "\n",
    "This one is almost a gimme because the `nx.connected_components()` function gives us almost exactly what we want: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have to remember to ask for it in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: a partition is a list of sets where every node is in exactly one of these sets. This is just what we have here, although it's a bit boring since we've only removed one edge and so there is still one connected component. If you like, you can try running the previous two cells a few times until you have more than one connected component so you can see what that looks like.\n",
    "\n",
    "Note that this feature whereby the connected components correspond exactly to our putative community labels is particular to the Girvan-Newman algorithm: other clustering algorithms may use different ways of generating their partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Recalculate the betweenness centrality of the links of the resulting graph.\n",
    "### D. Repeat from step B until no links remain.\n",
    "\n",
    "This implies that we need a loop to repeat this process $L$ times, once for each edge, and that we should keep track of the partitions generated. Straightforward stuff. We'll start with a fresh Karate Club graph since we removed some edges above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "partition_sequence = []\n",
    "for _ in range(G.number_of_edges()):\n",
    "    my_edge_betweenness = nx.edge_betweenness_centrality(G)\n",
    "    most_valuable_edge = max(G.edges(), key=my_edge_betweenness.get)\n",
    "    G.remove_edge(*most_valuable_edge)\n",
    "    my_partition = list(nx.connected_components(G))\n",
    "    partition_sequence.append(my_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the idiomatic construction of this `for` loop. Using `_` as the name for the loop variable tells the reader that we don't expect to do anything with the loop variable -- we just want to perform a task a specific number of times. One might be tempted to use a `while` loop here, but that way lie dragons: a mistake in a `while` loop can lead to infinite loops which are a headache.\n",
    "\n",
    "If we've done this right, we should have a partition for each step of the process, *i.e.* one for each edge in the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence), nx.karate_club_graph().number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we started with a connected graph, removing one edge probably doesn't disconnect the graph, so our first partition probably only has one community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the last partition should also be trivial, with each node in its own community:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(partition_sequence[-1]), nx.karate_club_graph().number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the modularity of each partition in the sequence\n",
    "\n",
    "We now have a sequence of partitions and a function to calculate the modularity of a partition. This is a great time to use a list comprehension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "modularity_sequence = [modularity(G, p) for p in partition_sequence]\n",
    "modularity_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sequence is then the modularity of the partition at each step in the algorithm. The first several entries in this sequence are effectively zero while there is only one community/component, then it jumps up once there is more than one community. We can use pyplot to visualize this relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(modularity_sequence)\n",
    "plt.ylabel('Modularity')\n",
    "plt.xlabel('Algorithm step')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the partition with highest modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we see a peak in the modularity sequence. This is the partition that maximizes modularity, and thus the output of the algorithm. We can use the `max` function to get the partition with highest modularity. Ideally we want to write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "best_partition = max(partition_sequence, key=nx.community.quality.modularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but we receive an error. Recall that a key function must take exactly one argument, the item in the sequence being evaluated, but the modularity function takes two arguments: the graph and the partition. We can fix this by writing a single-argument function to use as the key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_modularity(partition):\n",
    "    return nx.community.quality.modularity(G, partition)\n",
    "best_partition = max(partition_sequence, key=my_modularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Pythonauts will see a differet solution to this using the `zip` function to align the previously-generated partition & modularity sequences, but this solution is more explicit.\n",
    "\n",
    "So after all that work, what is the best partition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! The partition of the karate club graph with highest modularity actually has five components! Let's visualize them, using our code for partition maps we wrote back at the beginning of this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_partition_map(partition):\n",
    "    partition_map = {}\n",
    "    for idx, cluster_nodes in enumerate(partition):\n",
    "        for node in cluster_nodes:\n",
    "            partition_map[node] = idx\n",
    "    return partition_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_partition_map = create_partition_map(best_partition)\n",
    "\n",
    "node_colors = [best_partition_map[n] for n in G.nodes()]\n",
    "nx.draw_networkx(G, with_labels=True, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly how good is this five-community clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, best_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's higher than the \"ground truth\" communities we evaluated in section 3, which is a good sign, but for the specific problem of trying to predict the post-split community membership, a clustering into five groups is useless to us.\n",
    "\n",
    "### Get the best partition with a given number of communities\n",
    "\n",
    "One of the most useful parts of the Girvan-Newman algorithm is that it is also useful when we have a specific number of clusters we want. In this case, we know the karate club split into two groups, so let's get the partition in the sequence with two components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in partition_sequence:\n",
    "    if len(partition) == 2:\n",
    "        two_cluster_partition = partition\n",
    "        break\n",
    "\n",
    "two_cluster_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_cluster_partition_map = create_partition_map(two_cluster_partition)\n",
    "\n",
    "node_colors = [two_cluster_partition_map[n] for n in G.nodes()]\n",
    "nx.draw_networkx(G, with_labels=True, node_color=node_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this partition? We can get its modularity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.community.quality.modularity(G, two_cluster_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good -- comparable to the ground truth community labels. Let's compare these side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "two_cluster_partition_map = create_partition_map(two_cluster_partition)\n",
    "node_colors = [two_cluster_partition_map[n] for n in G.nodes()]\n",
    "nx.draw_networkx(G, with_labels=True, node_color=node_colors, pos=pos)\n",
    "plt.title('Predicted communities')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "node_colors = [G.nodes[n]['club'] == 'Officer' for n in G.nodes()]\n",
    "nx.draw_networkx(G, with_labels=True, node_color=node_colors, pos=pos)\n",
    "plt.title('Actual communities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the predicted community labels are pretty accurate, only differing on a couple nodes that, visually, seem like they could plausibly beling to either group. Zachary's original paper even explains the practical considerations of one of these mispredicted nodes: student 8 was very near receiving his black belt from Mr. Hi and thus did not want to leave the group even though several of his friends did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside\n",
    "\n",
    "The astute reader might note that there may be several two-cluster partitions in the partition sequence we generated. We assert the following to be true:\n",
    "\n",
    "1. For every integer 1 to N, the number of nodes, there is a partition in the sequence with that number of clusters\n",
    "2. Every partition in the sequence with the same number of clusters is the same\n",
    "\n",
    "Proving these is left as an exercise to the reader, but as a consequence of these being true, optimized implementations of Girvan-Newman clustering will only store one partition for each number of clusters. This is how the implementation in NetworkX works, only providing one partition for each number of communities greater than one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX Function\n",
    "\n",
    "`nx.community.girvan_newman(G)` will generate a sequence containing one partition of each size greater than one. Here we can see the first several are the same as those we generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.community.girvan_newman(G))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
