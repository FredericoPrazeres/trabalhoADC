{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de ADC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "paths = pd.read_csv('tsvs/paths_finished.tsv', sep='\\t')\n",
    "\n",
    "# Get the paths from the 4th column and split them by semicolons\n",
    "all_paths = paths.iloc[:, 3].str.split(';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós mais acessados do dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 9 most accessed nodes (excluding '<' backspace node):\n",
      "United_States     8896\n",
      "Europe            4362\n",
      "United_Kingdom    3904\n",
      "England           3332\n",
      "Earth             3223\n",
      "Africa            2795\n",
      "World_War_II      2301\n",
      "North_America     1884\n",
      "Germany           1769\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a list to store all nodes (excluding '<' backspace node)\n",
    "all_nodes = []\n",
    "for path in all_paths:\n",
    "    all_nodes.extend([node for node in path if node != '<'])\n",
    "\n",
    "# Count occurrences of each node\n",
    "node_counts = pd.Series(all_nodes).value_counts()\n",
    "\n",
    "# Get the top 4 most accessed nodes\n",
    "top_9_nodes = node_counts.head(9)\n",
    "print(\"Top 9 most accessed nodes (excluding '<' backspace node):\")\n",
    "print(top_9_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminhos mais frequentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: Brain -> Computer_science -> Information -> Communication -> Telephone, Count: 144\n",
      "Path: Bird -> Fish -> Whale_shark -> Shark -> Great_white_shark, Count: 86\n",
      "Path: Asteroid -> Earth -> Europe -> Norway -> Viking, Count: 76\n",
      "Path: Theatre -> India -> Mammal -> Zebra, Count: 74\n",
      "Path: Theatre -> Dance -> Animal -> Mammal -> Zebra, Count: 69\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to count occurrences of paths\n",
    "path_counts = {}\n",
    "for path in all_paths:\n",
    "    # Convert the path into tuples to make it hashable\n",
    "    path_tuple = tuple(path)\n",
    "    \n",
    "    # Exclude backspace nodes ('<') from the path\n",
    "    path_tuple = tuple(node for node in path_tuple if node != '<')\n",
    "    \n",
    "    # Increment the count for this path in the dictionary\n",
    "    if len(path_tuple) > 1:  # Exclude single-node paths\n",
    "        if path_tuple in path_counts:\n",
    "            path_counts[path_tuple] += 1\n",
    "        else:\n",
    "            path_counts[path_tuple] = 1\n",
    "\n",
    "# Get the top 5 most frequently taken paths\n",
    "top_paths = sorted(path_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "# Print the top paths\n",
    "for path, count in top_paths:\n",
    "    print(f\"Path: {' -> '.join(path)}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós com maior centralidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes with higher edge centrality:\n",
      "Node: United_States, Degree Centrality: 1623\n",
      "Node: Europe, Degree Centrality: 901\n",
      "Node: United_Kingdom, Degree Centrality: 882\n",
      "Node: England, Degree Centrality: 797\n",
      "Node: World_War_II, Degree Centrality: 669\n"
     ]
    }
   ],
   "source": [
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Create edges between consecutive nodes in paths\n",
    "for path in all_paths:\n",
    "    # Exclude backspace nodes ('<') from the path\n",
    "    path = [node for node in path if node != '<']\n",
    "    if len(path) > 1:  # Exclude single-node paths\n",
    "        edges = list(zip(path[:-1], path[1:]))  # Create edges between consecutive nodes\n",
    "        G.add_edges_from(edges)\n",
    "\n",
    "# Calculate node degrees (number of edges connected to each node)\n",
    "node_degrees = G.degree()\n",
    "\n",
    "# Sort nodes based on degree centrality\n",
    "sorted_nodes = sorted(node_degrees, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print nodes with higher edge centrality (top nodes based on degree centrality)\n",
    "print(\"Nodes with higher edge centrality:\")\n",
    "for node, degree in sorted_nodes[:5]:  # Print top 5 nodes with highest degree centrality\n",
    "    print(f\"Node: {node}, Degree Centrality: {degree}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
